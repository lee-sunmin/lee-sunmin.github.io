---
title: "[bigdata] Big Data on AWS - day 2,3"
categories:
  - bigdata
tags:
  - aws
  - bigdata
---


### Apache 하둡
범용 하드웨어 클러스터에서 대용량의 데이터를 분산 처리하는 데 최적화되어 있다.  
범용 하드웨어 : 우리 컴퓨터  

상대적으로 값싼 머신 여러대를 가지고 높은 성능   

하둡의 이점  
- 효과적으로 불확실성 처리 : 불확실한 데이터 - -> 스키마가 명확히 정의되지 않은 데이터. key/value 형태
- 데이터 다양성 관리


#### 모범 사례 2 (274pg)

** 시험 포인트 **  
상황 + 제약사항이 주어지고  
실시간 대시보드 - - > "키네시스"  
1회전달 - - > "카프카"  
(어제 말한 내용과 동일)  
******

#### 모범 사례 3: 데이터 압축 알고리즘(278)
snappy - orc, parque 와 효율이 좋음  
bzip2 - 추천  
gzip - 장기간 archiving 해야하는 경우에는 이거 사용하는게 좋음  

### Amazon EMR  

프로젝트 구성이 매우 쉬워진다. 일반적인 에코시스템 프로젝트를 자동 설치해준다  

HDFS, S3  
HDFS - 인스턴스 스토어, EBS+IS 가능  
S3 - 직접 파일 읽어서 처리, 저장 가능. 용량 확장이 알아서 되고 내구성이 뛰어나다. 처리를 *임시 클러스터*로 필요할 때만 쓰고 없으면 삭제시키는 것이 가능하다  


#### EC2 금액 측정 1가지    
1. on-demand  
2. RI - 1년, 3년 약정. 24시간 365일 매일 써야하는 애들이 사용  
3. spot instance - 

** 시험 포인트 **
작업이 *시간 내에 완료 되어야 한다*-> 스팟 사용하면 안돼  
작업이 있는데 중요도가 떨어져서 시간 안에만 끝내면 된다 -> 다음중에 가장 비용 효율적인 것은 무엇인가 ? 스팟 !  

스팟은 내가 원하는 시점에 얻어오지 못하는 경우가 발생 할 수도 있다-> 대부분은 매~우 안정적이다.  
예를 들면, 하루에 한번씩 데이터 끌고와서 분석해야 하는 경우라면 꼭 오늘 하지 않아도 되기 때문에 스팟성으로 사용해야 한다.  

실제 넷플릭스는 90퍼센트를 스팟 인스턴스로 활용한다.  
스팟이 아주 궁합이 잘 맞는게 데이터 배치성 처리
***********



#### 온프레미스 하둡 vs AWS 사용(287)  
1. 프로비저닝  
AWS는 클릭으로 편하게 솔루션 제공 가능하고, EMR은 다른 AWS 서비스들과 연계가 쉬움  
cloud watch는 인프라 모니터링 가능(EC2 인스턴스의 cpu/메모리 사용률 등)  
2. 관리  
적은 수의 관리자로 손쉽게 관리 가능  
3. (강사님 포인트)  
클라우드는 사용이 되는거에 맞춰서 비용을 맞출 수 있지만,  
온프레시므 환경은 인프라를 최고치로 맞춰놓고 가야한다.->손해  
특정 작업을 할 때 왕창 리소스 써야하는 경우가 클라우드에 적합(spot 성으로 그때그때 확 몰아서 처리하는 경우)  

1대 -> 10시간  
10대 -> 1시간  
비용 동일. 시간 크게 절약  

4. 보안  
VPC(Virtual Private Cloud?) endpoint  
특정 포트로 특정 ip address 에서 오는 요청만 EMR이 *허가* 하도록 하는 파이어홀? 규칙 사용 가능  
암호화 시 키 관리기술 - AWS 제공해주는 것 혹은 직접 관리  


#### EC2 - virtual machine
- VPC 사용 전
EC2 - EC2 (위험!) packet snipping에 취약  
- VPC 사용  
EC2 - VPC - 외부 통신  
그래서 VPC 가 보호 가능  

VPC 안에 띄울 수 있는 애들은 EC2, ELB, EMR, RDS, RedShift, ElasticCache, Lambda  
밖 - S3, DynamoDB, SQS  

원래는 VPC 안이랑 밖은 인터넷 게이트웨이 거쳐서 통신을 했었어야 했는데, 지금은 VPC 엔드포인트라고 해서 인터넷 연결하지 않고 안-밖 통신 할 수 있는 개념이 생겼다  

** 자격증 포인트 **

보안이 엄격하다. 퍼블릭 인터넷을 포함시키지 않고 싶다  
-> VPC Endpoint  
VPC 밖에 있는 애들이 안에 있는 애들이랑 프라이빗하게 연결 가능  
프라이빗한 네트워크로 VPC 밖에 있는 서비스들을 사용 할 수 있게 해주는 기능이 VPC endpoind(=Private Link)  
******  


5. 신뢰성  
성능이 떨어지거나 정상이 아닌 노드를 식별하고 자동 교체  

6. 유연성  
원하는 소프트웨어를 설정해서 띄우기가 쉽다  
- Immutable Infra Structure  


#### Immutable Infra Structure  
Infra structure를 1회용으로 사용하겠다. 한번 쓰고 버리겠다?  
클라우드처럼 가상화가 잘 된 곳에서 사용하는 건데, virtual machine이 됐던 뭐든 한번 쓰고 업데이트 하지 않고 폐기시키고 새 설정으로 하나 올린다. 그리고 끝나면 또 폐기  
좋은 이유? 업데이트를 하게 되면 업데이트 과정에서 여러 예상치 못한 것들이 발생한다. 그래서 여러대를 놓고 업데이트를 진행하면 구성이 조금씩 다르게 될 수 있다. 이런 상황을 없애기 위해 새로 띄운다 (새로 띄우는건 템플릿이나 스크립트에서 자동 생성)  

설정과 데이터는 폐기되면 안되기 때문에 폐기되지 않도록 밖으로 뺀다.  
데이터는 인프라와는 별도로 데이터 스토어(RDS, S3..)를 가진다.  

장점 : 실험, 테스트 하기가 굉장히 편해진다.  
워크로드에 따라 여러 가지 인스턴스 유형 중에서 선택 (평소보다 양이 많으면 더 강력한 파워의 클러스터 띄워서 사용 가능)  


7. 유연한 데이터 스토어(296)  
여러 데이터 스토어를 입맛에 맞게 사용 가능  

8. 통합  
다른 aws 서비스들과 원활히 통합된다.

#### EMR 아키텍처  

마스터노드(multi master - 3개로 구성)  
코어 노드(HDFS 포함해서 파일 시스템 가지고 계산도 하고 저장도 한다), 작업 노드(저장X 작업만 함)  

- 마스터 노드 : 메모리나 CPU가 균형을 맞추는 M 타입  
- 코어 노드 : M, C, R 타입이나 HDFS가 있는 애들  
- 작업 노드 : C, R  

304~ 그룹 별 정의  

#### 모듈 복습
1. 하둡을 구성하는 기본 요소?  
맵리듀스, yarn, hadoop common, hdfs
2. 하둡이 적합하지 않은 어플리케이션 2개  
어중간한 작은 데이터  
실시간은.. 잘 맞지 않습니다!(하둡보다 spark streams)  


### 모듈7

#### 모듈 7 문제 
1. 일시 클러스터 : ETL 작업 등  
장기 실행 클러스터 : 대화형으로 수행하는 경우 사용  
2. 현재는 3개짜리 멀티 마스터도 사용 가능하기 때문에 거짓
3. 작업 단계는 기본적으로 순차 실행된다.


### 모듈8

#### 프로그래밍 프레임워크(363)

#### Hive
분산 스토리지(S3, HDFS 등) 에서 대용량 데이터 세트를 관리하거나 쿼리를 실행 할 수 있는 SQL 유사 인터페이스  
가장 큰 장점 : SQL 언어와 유사  
데이터 분석 범위를 축소하도록 S3에서 데이터 분할 지원  

단점 : 저수준 MapReduce 기능에 대한 직접적인 액세스 제한  
(HQL으로 맵리듀스를 직접 컨트롤 하는게 제한적이다-> 엄청 크리티컬 하진 않음) 

- EMR의 Hive 이점(372)  
. 다른 AWS 서비스와 통합  
. 인스턴스와 분리된 메타스토어를 지정하는 옵션 제공  


Tez 사용하면 쿼리 지연시간 줄어든다(MapReduce보다)  

#### PRESTO
Presto는 표준 sql과 동일함  
매우 낮은 응답시간 (대화형 쿼리에 최적화)  
JDBC,ODBC와 호환이 좋다  
다양한 스토어(Hive, Cassandra, RDB 등)의 데이터에 대한 쿼리 실행 가능  

단점 : 대용량 테이블 2개를 조인할 때 신중한 최적화 필요  

배치 작업 처리에는 별로 좋지 않고, 단기간에 ad-hoc 성으로 필요한 데이터를 빨리 뽑아내는 방식에 최적화 되어 있음  
그래서 너무 대용량의 테이블을 조인해서 쓰거나 데이터가 굉장히 많은 (수백 TB)테이블 접근 시 out of memory 발생  


#### PIG
언어 : Pig Latin - 튜토리얼이나 샘플 많이 제공  

장점 : 여러가지 변환을 손쉽게 수행 할 수 있는 직관적이고 절차적인 구문  
MapReduce 작업으로 컴파일  
비구조화 및 반구조화 데이터 지원  
piggybank에서 사용자 정의 함수 제공  


단점 : 새로운 프로그래밍 기술 필요(배워야 함)  

#### SPARK
인메모리 처리 프레임워크   
장점은 무엇보다 빠른 속도  



### 모듈 9

#### 

실습 - 터널링 사용


### 모듈 10

인메모리 분석  
#### Spark
- 인메모리 데이터 마이닝과 빅 데이터 세트에 대한 쿼리를 빠른 속도로 실행  
- RRD(Resilient distributed datasets) : **메모리상에 데이터**를 중복해서 가지고 있으면서 병렬로 뭔가를 처리하기 쉽도록 한다, 여러 머신에서 병렬로 처리, 맵리듀스보다 빠른 속도로 결과를 낼 수 있다.  
- 배치, 대화식 및 스트리밍(마이크로 배치) 데이터 원본 지원
- 텍스트 및 하둡 파일 형식 지원  

#### Spark 프로그래밍 모델(435)
RDD 분산 객체 데이터 구조  
효율적으로 메모리 적재하고 병렬로 처리 가능하다  
맵리듀스 장점 살리면서 빠르게 작동하는게 장점  

- 내부적으로는 DAG(Directed Acyclic Graph) 사용해서 원하는 결과 가지고 온다 : 원하는 결과 빠르게,,   
현재는 DAG를 거의 의식할 필요 없이(튜닝에 힘 쏟을 필요 없음) 리소스를 좀 더 쓰더라도 결과를 빠르게 얻어내고 처리를 변환시키는 과정으로 진행  


#### DataFrame vs Dataset API
DataFrame : 행과 열로 구성된 데이터 세트  
R이나 Python에서 바로 사용 가능  

**DataSet**
RDD는 세부적인 처리가 가능하다고 하면, DataFrame은 추상화 시켜서 사람들이 다루기 쉬운 형태로 변환  
현재는 DataFrame만 알아도 괜찮음  


#### Spark SQL  
온디스크 또는 인메모리 데이터 처리  
(강의자료 참고)  

#### Spark Streaming  
스파크의 언어통합 API 사용해서 스트리밍 작업을 쉽게 할 수 있음  
스파크 자체가 스칼라(언어)로 만들어져 있는데, 파이스파크(파이썬으로 만들어진 스칼라 라이브러리)  

#### Apache Spark를 사용해야 하는 이유
- MapReduce보다 빠른 속도  
- 배치, 대화식 및 스트리밍 작업 지원
- 다양한 데이터 원본 사용
- JDBC, ODBC 커넥터 호환
- HiveQL 사용 쉬움, Java , Python

#### 고려사항
- 메모리 리소스를 많이 필요로 한다(계산노드나 코어 노드 R 타입 많이 사용)
- 단순 워드카운팅은 풀스캔이기 때문에 MapReduce나 하둡에서 사용하는 엔진들보다 특별하게 빠르다고는 볼 수 없는 경우도 있다. "풀스캔"  
- 마이크로 배치 기반 데이터 스트림 처리


#### 모듈 복습
Spark와 함께 제공되는 4가지 모듈 !!  
SparkSQL, Spark Streaming, SparkML, GraphX  

#### 기타
Scala repl : 대화처럼 콘솔에서 바로 작업


# Day2

## Module 11
레드시프트 - postgreql의 클러스터라고 생각  

기존 EC2 기반 필요한 소프트웨어 설치하는 기존 아키텍처  
서버리스는 서버 사용하지 않고 한가지 목적만을 위해 개발된 서비스(dynamoDB , lambda)  

서버리스는 정확하게 사용한 만큼만 비용을 지불하지만 EC2 기반은 쓰던 쓰지않던 띄워놓은 갯수/용량 만큼 비용 발생  


서버리스 특성  
서버 관리 없음, 유연한 조정, 유휴 용량 없음, 고가용성  

### AWS Glue
완전 관리형 카탈로그 및 ETL  
카탈로그 - 원시 데이터를 테이블 형태로 매핑시켜서 다른곳에서 사용 할 수 있게 해준다?  

EMR은 여러가지 다양한 JOB 들을 할 수 있는 반면에 Glue는 ETL 하나만 작업 할 수 있도록 단순화 시킴 

스파크에서 사용하는 코드들 가져와서 쓸 수 있음  

#### 1. 데이터 카탈로그  
영구적인 메타데이터 스토어  
테이블로 매핑하고 다른 서비스에서 가져다 쓸 수 있도록 관리  
하이브 메타스토어와 호환  

- 크롤러 기능  
여러 =종류의 데이터 소스에 있는 데이터를 읽어오면서 스스로 **스키마에 대한 정의를 추출하거나 추론 할 수 있음**  
인기 있는 유형에 대해 내장형 분류자 사용해서 알아서 포맷을 자동으로 판단 할 수 있음.  
임시 또는 스케쥴러에 따라 반복적으로 수행 가능  
서버리스 수행  

- 분류자 : 자동 스키마 추론(479)  
JSON이나 CSV 등에 대해 자동으로 스키마 추론 가능 

#### 2. ETL 엔진  
- DynamicFrame(DataFrame 개조) 이라는 독자적인 데이터 구조 사용  
일단 데이터를 넣어놓고 나서 이 데이터의 스키마를 나중에 동적으로 변경 할 수 있음  
데이터 유형(integer, string) 변경이 쉬움 - 일단 넣어놓고 분석해 가는 과정에서 데이터의 타입을 나중에 지정 가능  

- 개발 엔드포인트 : 일종의 노트북 인스턴스  
노트북 환경 제공하는 인스턴스를 띄울 수 있음  

glue endpoint auto sleep  

#### 3. 작업 오케스트레이션
많은 양의 작업을 수행 할 때 데이터들이 기대한 값이 들어있지 않은 경우가 있음. 입력 쪽에서 문제가 생겨서 처리가 진행되다가 에러가 나면서 중단되는 경우가 있는데 이럴 때 작업 북마크를 사용할 수 있음  
작업을 쭉 실행하다가 어딘가에서 멈추게 되면 **기록** 한다 : 작업 북마크  

S3의 파일 목록을 가져오고, 목록에 대해서 진행을 한다  
S3는 내가 시작하고 나서 그 이후에 보이게 되는 그런 파일들은 목록에서 제외(자기가 시작한 시점에 확인한 파일들에 대해서만 처리)하는 기능도 있음  

- 작업 북마크 옵션  
. 활성화 : 중단된 부분부터 다시 시작  
. 비활성화 : 중단한 부분을 무시하고 전체 데이터 세트 처리  
. 일시 정지 : 이전 데이터 파티션 처리(북마크 이동시키지 않음-결과를 S3에 저장하지 않음, 활성화/비활성화를 하기 전에 정상적으로 도는지 확인하기 위한 용도로 사용)  


**Glue 아키텍처 (493)**  

#### 데이터 자산 쿼리
** 시험 포인트 ** (495-6)  
어떤 상황이 주어지는데, 데이터 소스를 여러개 가져와야 한다.
레드시프트, s3, rds 에서 가져와야 함  -> Glue 사용 !!!  

S3에 판매기록이 쭉 있는데, 주문 기록만 있고 상품코드가 있는데 어떤 상품코드인지는 RDS에 있다. 상품 목록(s3)과 상품 코드(rds)를 조인해서 써야하는데, 
**여러 소스에 있는 데이터들을 조인 할 수 있게 만들어 주는게 Glue의 역할!**  
-> 여러 데이터 소스에 있는 데이터를 조합해서 사용하는 경우에 글루를 사용한다.  
-> 가장 빠르게, 가장 간편하게 수행 할 수 있는 것을 고르시오!  
</br>
비슷한게 EMR  
*******

### RedShift

#### 데이터 웨어하우스와 데이터베이스의 차이(505)  
기존 데이터베이스는 트랜잭션 워크로드를 위해 설계되었기 때문에 한 가지 작업에 장애가 발생하면 전체 작업이 중단된다.-> 대규모 데이터 처리에는 적합하지 않음  

분석용 데이터베이스는 트랜잭션에 얽메일 필요가 없고, 기존에 익숙했던 분석용 언어인 SQL을 사용하는게 데이터 웨어하우스  
트랜잭션 작업에 영향을 주지 않으며 분석작업을 수행 할 수 있도록 만들어짐  
중복된 데이터를 사용하는 것이 일반적, join 덜 사용하게 여러 테이블을 큰 하나로 몰아서 데이터 넣음 : 양쪽의 특정 컬럼들은 중복되지만 상관없다  
- 크로스 도메인 분석  
**데이터 웨어하우스는 여러 소스의 데이터를 통합**한다  


스파크와 레드시프트의 차이  
스파크는 본인이 데이터를 가지고 있지 않고 레드시프트는 자기가 데이터를 가지고 있음  


#### RedShift(적색편이)  
아마존의 데이터웨어하우스  
페타바이트 규모의 완전 관리형 데이터 웨어하우스 서비스  

- 관계형 데이터 웨어하우스  
- 대용량 병렬, 페타바이트 규모  
- 완전관리형  
- 저장장치는 HDD, SSD 중 선택하여 클러스터 구성 가능  
- 가격 저렴  


. RedShift Spectrum  
S3 내에 테이블 구조인 데이터와 R.S의 데이터를 조인해서 사용 가능  
S3 데이터를 마치 자기가 테이블로 가지고 있는 것 마냥 사용 가능  

#### 사용 사례  
- 빅 데이터에 대한 클라우드 ETL(519)  
EMR이 처리 할 수 있는게 압도적으로 많고, Glue는 제한적으로만 사용 할 수 있다  
- Firehose 통합  
apache log firehose redshift  
로그는 엘라스틱 서치 쓰는게 깔끔함  

#### 추가  
읽기 전용 복제본 read relpica  
굳이 실시간은 필요 없고 기존 데이터면 스냅샷 만들어서 분석하고 다 쓰면 없애  

** 자격증 포인트 **
redshift 관련 문제가 15%  
이 수업에선 그 문제에 대한 이야기를 제대로 다루지 않음  
테이블 구조 잡는법, 인덱싱 하는 법 (디테일)  

data warehousing on database 에서 자세히 다룸  

redshift performance tip - 상위 4-5 개 정도는 시험문제에 잘나오니까 꼭! 살펴보고 가기  

https://aws.amazon.com/ko/blogs/big-data/top-10-performance-tuning-techniques-for-amazon-redshift/

******


** 시험문제 포인트 **  
버킷에 대한 접근  
bucket policy  
vpc endpoint  
s3 버킷에 액세스 할 수 있는 vpc ip 지정  
버킷 policy 라는 란이 있는데,  
effect:deny(제일 강력, root 유저도 뺄 수 없어)  
action(s3의 모든 action을 거부하겠다)  
StringNotEquals - sourceVpce 가 아니면 모두 거부  
NotIpAddress - 해당 ip addr가 아니면 모두 거부

보안상 중요한 데이터가 있는데 레드시프트|emr 에서만 접근하도록 하고 싶다  
-> 버킷 정책을 가지고 할 수 있음  
-> vpc 내부에 잇는 애들만 프라이빗하게 접근하고 싶으면 vpc endpoint 사용

버킷 보호하는 방법에 대해서 집요하게 많이 물어봐  
특히, S3 관련해서 bucket policy, VPC endpoint 정확한 이해 필수!  
******


## 모듈 13  
(+) 시험 준비 할 때 보안쪽도 잘 해야해  
스토리지나 기기도 엄격한 관리에 따라 폐기  
aws.amazon.com/security  

#### Amazon EMR 및 Amazon VPC  
VPC endpoint  
EMR 클러스터를 퍼블릭 서브넷에 두는건 아주 좋지 않습니다. private subnet에 두는게 좋음  
아니면 public subnet 터널링 설정해서 접근  

** 시험 포인트 **  
인터넷 게이트웨이 통해서 왔다갔다 하는건 권장하지 않고 VPC endpoint 사용해서 프라이빗하게 접근하는거 권장  
*******


#### EMR 보안  
AMI account 통해서  
API 요청에 대한 인증 필요  

외부에서 EMR의 마스터 노드에만 접근 가능하고, 코어노드는 접근 할 수 없음  
오직 클라이언트를 통해서 마스터노드와만 통신이 가능하다  

- EMR 기본 보안 그룹  
마스터와 슬레이브간 통신을 위해 임시 포트 개방 ...   

- 세부 액세스 제어  
태그를 사용하여 세부 액세스 제어 활성화  
태그 값을 통한 작업 허용 또는 거부  

(553)  
태그를 추가하고 제거하는것을 거부하겠다는 뜻임  
stringNotEquals : department에 dev 가 있는 것만 허용이 가능하고 나머지는 거부  
명시적으로 사용하기 위해서는 allow를 반드시 가지고 있어야 한다. 그런데 allow가 있어도 deny가 되면 접근 불가  


##### IAM(556)  
사용자, 그룹, 역할, 정책  

1. 루트 계정 생성  

2. 관리자 그룹 생성
관리자 그룹 생성하여 관리자 그룹에게 admin 권한 부여  
Maria(회사 계정 생성), IAM 유저에게 권한 부여, 관리자 그룹 권한 부여하지만 그룹 권한 중 세부적으로 권한 축소 가능(꼭 필요로 하는 권한만 가질 수 있도록)  
3. 그 외 그룹 생성
한시적으로 임시 권한(역할) 가능, 사람 뿐 아니라 EC2에게도 권한 줄 수 있음  

- IAM 사용자 및 정책
자격 증명 연동을 해서 구글 아이디로 특정한 s3 bucket에 있는 파일을 읽을 수 있게 해줄 수 있음  

- IAM 역할  
기본 역할은 EMR_DefaultRole  
S3 같은 서비스에 접근하는 권한을 EC2 인스턴스에게 부여 가능  

- IAM 모범 사례  
Multi-Factor Authentication(MFA) 사용하는 것을 권유  

마스터 계정 평소에 절대 사용하지 마세요..-> 탈취당하게 되면 해커가 한꺼번에 모든 리소스를 한번에 지울 수 있음  
평소에는 파워유저나 필요 시 admin 유저를 IAM으로 만들어서 사용  

##### Kerberos 인증  


#### S3 암호화(570)

** 시험 포인트 **
SSE-S3
SSE-C
SSE-KMS
*******


 
#### AWS KMS  

SSE-KMS의 이점  
암호화 키를직접 생성 및 관리할 필요가 없어서 안정적이고 견고하게 사용 가능  

AWS Key Management Service 

** 시험 포인트 **  
기존에 키 관리 인프라를 소유하고 잇는데 AWS 에 하고싶다. - SSE-C  
키를 생성만 키 관리 인프라에게 하고 관리만 맡기는 것도 가능하다  
********


IAM은 AWS의 권한과 인증을 담당하는 서비스  
ip 주소에 따라 생산자/소비자를 허용하도록 할 수도 있음  

### Amazon DynamoDB 보안  
(590)  
condition *  
forAllValues : StringEquals:LeadingKeys  
테이블의 리딩키가 유저아이디와 같은 경우에만 통신을 허용한다  

StringEqualsIfExists:SPECIFIC_ATTRIBUTES  
// 아이디 값이 일치하는 경우에만 테이블의 특정 로우에 있는 값을 읽어 올 수 있도록  

(591)  
이것만 허용해라. 라는 화이트리스트 방식  
stringequals 라는건 userId와 TopScore와 명시적으로 같을 때만 값을 읽어 올 수 있도록 해라  

#### 웹 자격 증명 연동 사용  

** 시험 포인트 **  
한 문제 이상 나옴
스마트폰 어플리케이션 만들었는데, 이 어플리케이션에 game score를 알고 싶다.
가운데 서버로직 쓰지 않고 클라이언트가 직접 dynamoDB 에 접근 할 수 있다. 이때 권한을 STS(AWS security token service)에서 가져 올 수 있다.  
로그인한 정확한 자기 아이디에 해당하는 아이템만 읽어 올 수 있다.    

위에 있는거 사용하나봄 ?   
******

### RedShift 보안 
기본적으로 암호화가 활성화되지 않는다. 설정 필요  

#### 보안 마무리
** 시험 포인트 **  
VPC를 통해서 어떻게 접근제어?  
IAM 통해서 어떻게 접근제어?  
F..Access Control  
VPC endpoint : 개념 명확! 하게 이해하고 가야 함. 굉장히 잘나옴  
************


## Module 14 : 빅데이터 비용 관리 

VPC 내부에 하면 밖으로 나가는 데이터를 줄이기 때문에 비용면에서 유리  

#### DynamoDB
** 시험 포인트 ** -> 확인(648)  

- DynamoDB Streams  

** 시험 포인트 **  
시험에서 가격 물어보기도 하는데 지문이 제공된다  
계산하는 방법만 알고 있으면 된다  
******

- Autoscaling  
사용량이 완만하게 왔다갔다 할 때, 실제 프로비저닝 하는 양은 올라가는 시점보다 약간 늦게 올라간다(내부적으로 리소스 확보하는 시간이 필요) 그리고 줄어드는 시간도 약간 늦게 내려온다  

만약 급하게 처리용량이 변하면 평소에 spot을 많이 잡아줘야한다. 그래야 확장하는데 필요로 하는 시간을 벌어서 처리 가능  


# 시험 정보 

AWS Bigdata Analytics certification  
연습 시험도 있나본데  

specialty - 쉽지 않은 시험이다  

(1) 시험 안내서를 쭉 봐야한다. 여기에 시험 범위같은 것이 쭉 나와있음  
합격 선이 750점(75/100) 

(2) 샘플 문항을 꼭 풀어본다.  
문제의 보기들이 의미하는 바를 정확히 알고 있어야 한다  
답이 될 수 있는건 왜 답이 되고, 답이 되지 않는건 왜 답이 되지 않는지 명확히 이해 필요  

온라인 상 유료 40달러 내고 볼 수 있는 연습문제가 있음. 20문제 1시간  


1. 중첩 JSON S3에 있는 데이터와 Redshift에 저장된 데이터를 같이 분석 할 수 있는 것 ?  
**경제적으로 적절한 자동화 솔루션**  

A) EMR도 개발이 필요해서 경제적이지 않아  
B) lambda는 절대 답이 될 수 없음. 프로그램 짜고 해야함, 경제적이지 않아  
C) Glue !! 이거임  
D) Redshift COPY - CSV면 얘도 되는데 중첩 JSON이라서 안돼.  



2. 클릭스트림 데이터를 키네시스 데이터 스트림으로 보냄.  
**확장 할 수 있어야 함**, **경제적인 서비스**  
스트림 어쩌구 -> 키네시스 데이터 스트림  

A) EC2 ~~ 나오면 답이 되기가 힘들어. 왜? EC2는 절대 경제적이지 않음. 시간과 인건비 생각  
B) KCL 사용 -> 직접 lambda나 EC2 가지고 어플리케이션을 만들어야 한다는 말. 경제적이지 않음?  
근데 lambda가 EC2 인스턴스보다 나음  
C) EC2 - lambda보다 별로, 다른거 내용 자체가 틀려서 C  
D) lambda  

답은 C  

핵심은 뭘 기준으로 해서 특정 유저의 클릭 히스토리를 관리 할 것인가?  
카운터를 유지관리

3. dynamodb를 데이터베이스로 쓰는데 pdf가 1-10mb니까 다이나모에 넣기는 커  
파일은 s3에 넣고 키를 다이나모디비의 속성으로 사용  

B번.  

4. **지연시간이 가장 짧은** sagemaker로 실시간 추론을 하겠다  
사기방지 기능은 거의 실시간으로 해야한다.   
A)EC2 인스턴스에서 실행되는 Kafka 소비자 사용  
B)Lambda 함수 생성  
C)사기방지 기능은 거의 실시간으로 해야하는데 firehose는 1분정도 싱크타임이 있어서 안돼  
D)SNS는 시간이 보장되지 않아. 느릴땐 느리고 빠를땐 빠르다  

나능 A 하고 싶은데 답은 B 일 것 같음.->lambda..왜? EC2보단 lambda가 답인 경우가 많아  
비용이 같은거 처리할 때 카프카가 조금 더 비싼 편이다..?  


5. 기존 온프레미스에서 쓰던거 들고와서 emr로 쓰겠다  
B) 만들어진 jar가 있으면 버전에 맞게 컴파일해서 다시 쓸 수 있어요  

6. **스파크에서 동일한 데이터를 반복해서 쿼리한다**
-> 스파크 데이터 프레임으로 로드하는게 가장 빠릅니다.  
A)
b)
c) 반복해서 쓸 때는 dataframes으로 로드해서 여러번 쓰는게 가장 빠르다
d) 전혀 상관없어
e) 기능이 있긴 한데 풀스캔 통해서 검색하기때문에 빠를수가 없어  

쌤의 답 - C,E
핵심은 동일 데이터 반복 처리인데, select도 cache를 쓰고 dataframes도 메모리에 로드해서 쓰니까 더 빠르게 쓸 수 있다  

**S3 Select**
S3에 있는 데이터에 대해 안에 있는 데이터 포맷에 대해 직접 쿼리를 할 수 있도록 만들어진 기능  
아테나랑도 흡사한데 lambda에서 가져 올 수 있고 EMR에서도 가져 올 수 있음  

7. **1분 미만의 지연 시간으로 표시되어야 한다**  
문제의 제약사항을 빨리 파악 할 필요가 있음  

A)  
B)  
C) kinesis streams : 샤드를 확장하거나 줄이는 방법으로 준 실시간에 준하는 시간으로 보장 가능  
D) SNS? SQS 는 시간을 보장해주지 않아. 1분 이상 걸린다 안걸린다 보장 불가능임
EC2인스턴스? (X) MySQL(X)  

정답 : A  

firehose 성능이 개선되어서 1분 안쪽으로 들어온 것 같음(1분 미만 커버가 된다.)  
풀이 잘 모르겠다 !!  


8. csv파일, S3에 저장, 전날까지의 최신 데이터 반영 -> 실시간 아님, 1일 배치  

quickSight 기능인데, 확인 필요  

정답 - C : 데이터 세트가 매일 새로 고쳐지도록 예약 할 수 있다.  
 
9. EMR 루트 볼륨이 암호화 되지 않았다. (예전에도 나온 문제) **최대한 빨리 암호화**  
A) 유휴 시 암호화(저장 시 암호화), S3도 데이터 집어넣을 때 암호화 시켜서 넣어야 하는데 이건 도중부터 암호화 시켜서 넣는다는 거니까 뭔가 안될 것 같음    
B) 정답

마스터 노드가 사용하는 EBS 노드 - EBS는 생성 될 때만 암호화 가능 생성 된 후에 암호화 한다는거 말이 안돼  

10. EMRFS 사용하는 EMR 클러스터에서 presto 쿼리  
액세스 권한을 다 따로 부여하네. 보안  
A)   
B) Apache Ranger ?? 
C)  
D) Ranger에서   


**Apache Range**  
하둡 내부에서 관리하는 메타스토어를 마치 DB에 테이블별로 권한 주듯이 할 수 있음 


**문제 풀이에 읽어야 할 문서들 링크를 보세요. 10문제 정확하게 파악해야 한다.**  


### 온라인으로 볼 수 있는 연습시험
어차피 똑같은 문제 계속 나오니까 한명이 캡쳐해서 같이 나눌 수 있음  

cloud preticional ?? -> 모든 시험 50% 쿠폰과 연습시험 무료 쿠폰  

170분짜리 시험인데 30분 연장 할 수 있는 방법이 있음  
http://bit.ly/MORE_TIME  
시험장 갈 때 포도당이 들어있는 음료수를 꼭 챙겨가십쇼.. 핫식스.. 에너지 드링크..  

이러닝 코스랑 같이 준비하세요.  



