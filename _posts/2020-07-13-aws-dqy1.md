---
title: "[bigdata] Big Data on AWS - day 1"
categories:
  - bigdata
tags:
  - aws
  - bigdata
---



S3DistCP

- S3DistCP 압축 지원
데이터를 지정한 압축 포잿으로 지정해서 저장 할 수 있음.



#### Apache Sqoop을 사용한 데이터 전송
HDFS(Hadoop Distribution File System)에서 RDB로 혹은 양방향 전송 가능하다.  


#### 데이터 전송 옵션

VPN 연결이 가능하다.  
사내 데이터 센터에 ipsec 이 있으면 AWS 를 프라이빗하게 쓸 수 있는 VPN 연결 제공해준다. 

성능이 보장되지 않는다는 단점이 있다.  
해결을 위해 AWS Direct Connect 라는 서비스가 물리적 회선을 제공해준다.  
장점은 안정성.  회선 분리하고 싶으면 파트너 통해서 분리도 가능  
AWS에서 밖으로 데이터를 내보낼 때 쓰는 비용이 그냥 인터넷을 사용하는 것보다 적기 때문에 비용절감.  

AWS 비용 발생 3가지  
1) 컴퓨팅 - CPU 사용하는 작업  
2) 저장 - S3와 같은 저장장소를 얼마나 사용 할 것인가  
3) 데이터 전송 - AWS로 데이터를 보내는 것은 공짜고, 외부로 데이터를 보내는 것에 대해서만 비용이 발생한다.  

#### ** 시험문제 포인트 **  
데이터 전송 옵션 !  
  
  
마이그레이션을 몇일에 진행 하는데 몇시 안에 끝나야 한다(시간제약)
데이터를 옮겨야 하는데 다음중에 어떤 것을 사용할 것인가?

1) 시간성 제약, 단발성  
단기간에 데이터 왕창 올려아 한다 - > 스노우볼. 직접 하드웨어를 받아서 데이터를 넣고 보내는 방식  
2) 실시간도 허용이 되는데, ***지속적***으로 받아야 한다 - > 다이렉트 커넥트  
3) 좀 늦어져도 상관 없는데, ***시간에 대해서 아무 엄격하지 않다*** - > 그냥 인터넷을 통과하는 s3 멀티파트 업로드나, vpn 사용 가능

어떤 때에 무얼 쓰느냐? 를 적절하게 사용해야 함.


데이터 마이그 할 수 있는 솔류션(red shift)  
파일로 옮기면(s3)  
S3 -> EMR에서 제공하는 HDFS

S3는 오브젝트 스토리, 웹 하드처럼 사용.  
내구성이 엄청 좋다. 1년동안 데이터가 깨지지 않을 확률이 9가 11번 있는 99.999x  
여러개의 복제를 만들어서 복제본들이 서로서로 깨지지 않았는지 체크를 함으로써 손상이 된 복제본이 있으면 자동으로 교체하는 방식 사용해서 내구성 유지하고 있음.  
여기 s3 데이터를 넣으면 깨질 일이 없다고 보면 된다.  
5T 1만개를 천만년동안 보관했을 때 하나가 깨질랑말랑할 확률이다.  


****

#### AWS 데이터 전송 솔루션  

Snowball Edge - 한 개당 100TB  
Snowmobile - 컨테이너 하나당 PB (데이터 센터 통째로 옮겨오는데 사용)  


#### AWS IoT  
사물 인터넷에 사용되는 디바이스를 관리 할 수 있는 기능 제공  
여러 디바이스로부터 데이터 수집, 저장, 분석(필터링) 가능  

Lambda, kinesis, s3, machine learning, dynamo db와 저장 및 통합해서 사용하는 것이 가능  

작동 방식  (교재 참고)  

#### AWS IoT의 기능 : 규칙 엔진  
자체적인 문법(where ..)를 가지고 있다. 즉, 필터링 할 수 있는 문법 제공  
이걸 통해서 어떤 값이 몇분 이상 지속됐다 -> 다른 시스템으로 메시지 이전 가능(가능한 범위는 교재 참고)  


### Module 3
#### Kinesis  
데이터가 생산 될 때마다 보내는 방식 : 스트리밍(Streaming)  
스트리밍과 배치 사이 - 마이크로 배치(어느정도 스트리밍)  

배치 처리 : 유한 데이터를 지원하도록 설계  
어느정도 데이터를 모았다가 전송하기 때문에 압축을 하거나 포맷을 바꿔서 효율적으로 통신 할 수 있음.  
스트림 처리 : 연속 데이터를 지원하도록 설계  
최대한 빨리 처리하도록 할 수 있음. 단순히 시간만 빠른게 아니고 너무 데이터의 양이 많아서 배치로 처리가 안되는 경우 스트림 처리를 통해 그때그때 쌓인 데이터를 전송하기도 한다.   
  
#### 스트리밍 데이터를 솔루션에 사용해야 하는 이유
1. 수집과 처리의 분리
2. 복수 스트림의 동시 수집
3. 메세지의 순서 유지- fifo (kafka와 유사)  
SQS는 순서의 보장이 안된다.  
4. 병렬 소비  

#### 스트림 처리 어플리케이션 특징
(강의 자료)  
lambda 아키텍처 구현 : 상태를 공유하지 않은 상태에서 전달, 공유 ?  

#### 빅데이터 스트림에서 데이터 윈도우 작업  
1. 고정 : 고정크기의 임시길이
2. 변동 : 생산되는 양이 들쑥날쑥 할 때, 특정 양이 모일 때까지 기다렸다가 분할하는 방식으로 할 수 있음  


### Amazon Kinesis
** 자격증 포인트 **  
실시간 어쩌구.. **실시간**이라는 단어가 나오면 거의 kinesis ***  
지금은 managed kafka , kinesis 두 가지 선택지  

**1회 전달 보장 - Kafka**  
kafka 단점은 비용이 kinesis보다는 더 발생한다는 단점이 있음.(리소스 많이)  
  
**kinesis는 순서 보장, 전달 보장하지만 1회 전달이 보장되지 않는다**  
데이터가 나갈 때 동시에 2개를 가져 갈 수 있음.  


****
kinesis 4가지(강의자료 참고)  

kinesis data streams는 단순 데이터 저장  
데이터를 수집 및 스트리밍 하여 순서대로 실시간 처리  

### Data Firehose
스트리밍 데이터를 캡쳐하고 변화하여 아래 4가지로 로드 가능   
kinesis data analytics, s3, redshift, elasticsearch service  
  
- 데이터를 로드하기 전에 배치 처리, 압축 및 암호화 할 수 있다  
orc, parque  


*추가 설명-orc, parque*  
데이터를 column으로 저장을 해서, select 할 때 특정 column만 읽어오고 싶을 때 i/o의 부담이 줄어든다.  
그리고 여러 column을 선택했을 때, 비슷한 포맷?일 경우가 많아서 압축에 굉장히 용이하다.(압축효율 향상)  

#### 작동 방식 및 이점

스트리밍 데이터를 캡쳐하여 Firehose Rest API 사용하여 데이터 제출  


이점  
1. 지속 관리 불필요  
2. 지연 시간이 거의 없는(x 60초정도) 준실시간 응답  
3. 사용 편의성

개념 (강의자료 참고)
Firehose 전송 스트림  
- Firehose 기반 엔티티
- 샤드 프로비저닝 없음  
- 파티션 키 없음

**데이터 생산자**  
데이터 생산자는 전송 스트림에 레코드를 전송하는데,
키네시스에서 제공하는 생산자 라이브러리를 사용하거나 로그 수집기나 데이터 수집 툴에서 (flume,..) 키네시스로 데이터를 보낼 수 있는 기능 제공하니 그거 사용한다.  

### Kinesis Data Streams  
데이터 저장 + 처리(포맷 변경, 필터링)  

firehose보다 훨씬 높은 준실시간 성능(수초 이내)  

kinesis 생산자가(File로 떨구거나 log 수집기 이용해서 데이터 밀어넣음) -> kinesis streams에 넣고 -> kinesis 소비자(kinesis 소비자 library 사용해서 개발 많이 함)가 생성된 데이터 사용 -> 붙여서 쓸 수 있는 서비스의 제약은 거의 없다  

#### Kinesis Data Streams를 통한 데이터 이전 방법
(강의자료 참고)  
map reduce 과정과 동일  

#### Kinesis Data Streams 어플리케이션 구축 - 어렵당 .. 
(강의자료 참고)  
EC2 인스턴스의 갯수를 늘렸다가 줄였다가 할 수 있음-오토스케일링(Auto Scaling)  

#### 커넥터 라이브러리
이걸 사용해서 키네시스에 쌓인 데이터를 여러 서비스로 넣을 수 있음  

firehose는 S3 Redshift EMR ES 4개정도만 지원했는데  
이건 좀 더 다양하게 지원한다.

단, 오토 스케일링을 통해 용량이 확장 될 수 있도록 설정을 해줘야 함  


#### firehose vs streams
** 시험 포인트 **  
streams - **거의 실시간, 1초 미만**  
firehose - 동기화 되는데 1분 이상 걸려도 상관이 없다.  
붙여도 되는거 S3, RedShift, ES  
대신 관리가 전혀 필요없다.
******  

### Kinesis Video Streams

text 기반이 아닌 binary 기반 데이터 사용  
영상분석 서비스와 연결해서 사용 할 수 있는 기능 가지고 있음  

amazon recognition 같은 AI 서비스와 연결해서 사용 할 수 있다  


### Kinesis Analyrics(스트리밍 분석)  

지금까진 받고 처리해서 넘겨주는 것 까지 했는데.  
필터된 애들만 분류 하고싶을 때 사용 할 수 있는 서비스  

가장 큰 특징은 SQL 통해서 데이터 필터링 가능  
실시간성(1초 미만), 데이터 처리량에 따라 탄력적 확장  

#### 스트리밍 소스에 연결

- firehose, streams 둘 다 가능함  
- json, csv, 변수 열, 비구조화 텍스트 -> 결국 text 데이터만 대상으로 할 수 있다!  
- 자동으로 스키마 추론 - 테이블 형태로 access 할 수 있도록 만들어주는 기능  


#### SQL을 사용하여 스트리밍 데이터 처리
**최소 한 번** 처리 의미 체계 - 하나 넣었는데 두개 나올수도 있다.  
1회 전달이 보장이 안된다.. !  

#### 처리된 데이터를 연속적으로 전송
처리와 전송을 분리 할 수 있음  

### 기타 스트림 처리 어플리케이션  

1. Apache Spark Streaming  
스트리밍 데이터를 1초 미만의 마이크로배치로 분할하여 처리  
다양한 변환, 다양한 데이터 소스, 다양한 데이터 저장소 선택하여 사용 가능  
kafka, flume, twitter, kinesis, s3, tcp/ip 로부터 데이터 읽을 수 있음  

2. Apache Kafka  
실시간 성으로 들어오는 데이터를 안전하게 두고 **순서를 지키면서 1회 전달을 보장**해 준다

3. 그 외  
EC2 또는 EMR에 설치 가능한 도구(자바 런타임 환경)  
Flume, Storm, Samza, Flink  


#### 기타
HUGI(Hurry up Get I..?)  
인스턴스 한대가 10시간 동안 돌아야 끝나는 작업  
병렬이 가능하면 인스턴스를 10대 사용해서 1시간만에 완료  
가격은 양쪽이 똑같다. 시간이 줄었으니까?????  

장기 분석은 S3, 단기 분석은 RedShift


#### 어떤 스트림 스토리지를 사용해야 하는가?
(강의자료 참고)  
** 자격증 포인트 **  
가장 느린애 - SQS(표준,FIFO)  
실시간성이 잘 보장 안되는애 - firehose  
제일 빨리 도착하는애 - Kinesis streams, Kafka  

(사진 참고)  
****

질문  
1. 어느정도 처리?
2. 확장 축소 가능?
3. 내결함성?
4. 전송 보장?
5. 어떤 프로그래밍 언어 지원?
6. 누가 관리?(관리에 대한 부담감)  

#### 모듈 복습 문제

1. kinesis data streams 샤드  
샤드는 내부적으로 인스턴스와 동일  
고정된 처리용량을 지닌 처리 유닛  
읽기는 초당 1mb., 쓰기는 2mb 라는 고정된 처리용량 지니고 있음  

2. kinesis 이점 두 가지  
높은 처리량, aws 서비스 통합, 사용 및 관리의 용이성, 저비용, 준실시간 성능

3. Kinesis는 대용량 데이터 파일의 스트리밍에 적합한가?  
거짓!  
대용량 데이터 파일 스트리밍...?  
파일 덩어리 하나가 큰거 처리는 적합하지 않고 여러개의 작은 파일 여러개를 처리하는 것에는 적합하다.  

자격증 시험 문제는 절대 이런식으로 나오진 않아요 ^^;  
다만, 파일이 2mb 안쪽의 파일이 여러개 생성됐다. 어떻게 처리할까? 이런건 물어 볼 수 있음.  



### 실습  
analytics 이용해서 필터링 하고, firehose 써서 s3 버킷에 넣는거  


### 모듈 4

#### 